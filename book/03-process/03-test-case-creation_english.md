# 3.3 Test Case Creation

## The Importance of Test Case Creation

In AITDD, test cases are a crucial element that determines the quality of the implementation. The quality of the code generated by the AI largely depends on the comprehensiveness and accuracy of the test cases, so it is important to design comprehensive test cases at this stage.

## Principles of Test Case Design

### 1. Ensuring Comprehensiveness

#### Feature Comprehensiveness
- **Happy Path**: All expected behaviors
- **Sad Path**: Error handling and validation
- **Boundary Values**: Boundary conditions for input values
- **Edge Cases**: Special conditions or exceptional situations

#### Test Level Comprehensiveness
- **Unit Tests**: Tests for individual functions/methods
- **Integration Tests**: Tests for the interaction between components
- **End-to-End Tests**: Complete execution of user scenarios

### 2. Clear and Specific Expected Values

```markdown
❌ Bad Example: "An error should occur"
✅ Good Example: "A status code of 400 and the error message 'Email already exists' should be returned"
```

### 3. Independence and Reproducibility
- Each test case can be executed independently
- Not dependent on the test execution order
- Not dependent on the external environment

## Standard Format for Test Case Documents

### Basic Template

```markdown
# [Feature Name] Test Case Specification

## Test Overview
- **Target Feature**: Name of the feature being tested
- **Test Objective**: What to verify
- **Prerequisites**: Prerequisites for test execution

## Test Case List

### TC001: [Test Case Name]
- **Category**: Happy Path/Sad Path/Boundary Value
- **Objective**: What this test will verify
- **Prerequisites**: The state before test execution
- **Test Data**: Details of the input data
- **Execution Steps**:
  1. Specific step 1
  2. Specific step 2
- **Expected Result**:
  - Details of the expected behavior
  - Expected output value
- **Post-conditions**: The expected state after test execution
```

### Concrete Test Case Example

#### Example: Test Cases for User Registration Feature

```markdown
# User Registration Feature Test Case Specification

## Test Overview
- **Target Feature**: New User Registration API (POST /api/users)
- **Test Objective**: To verify all patterns of new user registration
- **Prerequisites**: The database is in its initial state, and the API server is running.

## Test Case List

### TC001: Normal User Registration
- **Category**: Happy Path
- **Objective**: To verify new user registration with valid data
- **Prerequisites**: test@example.com is not registered
- **Test Data**:
  ```json
  {
    "email": "test@example.com",
    "password": "SecurePass123!",
    "password_confirmation": "SecurePass123!"
  }
  ```
- **Execution Steps**:
  1. Send the test data to POST /api/users
  2. Check the response
  3. Check the state of the database
- **Expected Result**:
  - Status code: 201
  - Response:
    ```json
    {
      "id": any positive integer,
      "email": "test@example.com",
      "created_at": "datetime (ISO 8601 format)"
    }
    ```
  - Database: A new record is created in the users table
  - The password is saved in a hashed format
- **Post-conditions**: The user is successfully registered and can log in

### TC002: Duplicate Email Address Error
- **Category**: Sad Path
- **Objective**: To verify error handling when registering with an existing email address
- **Prerequisites**: test@example.com is already registered
- **Test Data**:
  ```json
  {
    "email": "test@example.com",
    "password": "AnotherPass456!",
    "password_confirmation": "AnotherPass456!"
  }
  ```
- **Execution Steps**:
  1. Send the test data to POST /api/users
  2. Check the response
  3. Check the state of the database
- **Expected Result**:
  - Status code: 400
  - Response:
    ```json
    {
      "error": "validation_failed",
      "details": [
        {
          "field": "email",
          "message": "Email already exists"
        }
      ]
    }
    ```
  - Database: No new record is created
- **Post-conditions**: No impact on existing user data

### TC003: Password Mismatch Error
- **Category**: Sad Path
- **Objective**: To verify error handling when the password and confirmation password do not match
- **Prerequisites**: Use a new email address
- **Test Data**:
  ```json
  {
    "email": "new@example.com",
    "password": "SecurePass123!",
    "password_confirmation": "DifferentPass456!"
  }
  ```
- **Expected Result**:
  - Status code: 400
  - Error message: "Password confirmation does not match"

### TC004: Invalid Email Address Format
- **Category**: Sad Path/Boundary Value
- **Objective**: To verify email address format validation
- **Test Data Set**:
  - "invalid-email" (no @)
  - "test@" (no domain part)
  - "@example.com" (no local part)
  - "test..test@example.com" (consecutive dots)
- **Expected Result**: All should result in a 400 error

### TC005: Insufficient Password Strength
- **Category**: Sad Path/Boundary Value
- **Objective**: To verify password strength validation
- **Test Data Set**:
  - "short" (less than 8 characters)
  - "onlylowercase" (only lowercase letters)
  - "ONLYUPPERCASE" (only uppercase letters)
  - "12345678" (only numbers)
  - "NoSymbol123" (no symbols)
- **Expected Result**: All should result in a 400 error

### TC006: Required Fields Not Entered
- **Category**: Sad Path
- **Objective**: To verify validation for required fields
- **Test Data Set**:
  - no email
  - no password
  - no password_confirmation
  - empty string cases
  - null cases
- **Expected Result**: All should result in a 400 error

### TC007: Boundary Value Test - Email Length
- **Category**: Boundary Value
- **Objective**: To verify the character limit for email addresses
- **Test Data**:
  - 254 characters (maximum allowed)
  - 255 characters (exceeds the limit)
- **Expected Result**:
  - 254 characters: successful registration
  - 255 characters: 400 error

### TC008: Rate Limit Test
- **Category**: Non-functional
- **Objective**: To verify the rate limit for concurrent registrations
- **Execution Steps**: Send a large number of requests in a short time
- **Expected Result**: 429 error if the limit is exceeded

### TC009: Database Connection Error
- **Category**: Sad Path/Infrastructure
- **Objective**: To verify the behavior during a database failure
- **Prerequisites**: The database is unavailable
- **Expected Result**: 500 error and error log output

### TC010: CSRF Token Validation
- **Category**: Security
- **Objective**: To verify the prevention of CSRF attacks
- **Test Data**: No CSRF token, or an invalid token
- **Expected Result**: 403 error
```

## Test Case Creation Workflow

### 1. Extracting Test Cases from the Specification Document

```markdown
Each item in the specification document → Corresponding test case

■ Functional Requirements
- Basic features → Happy path test cases
- Validation → Sad path test cases
- Input restrictions → Boundary value test cases

■ Non-functional Requirements
- Performance → Load test cases
- Security → Security test cases
- Availability → Failure test cases
```

### 2. Procedure for Test Case Design

#### Step 1: Organize Test Perspectives
```markdown
## Test Perspective List

### Functional Perspective
- [ ] Behavior with normal input
- [ ] Input value validation
- [ ] Error handling
- [ ] Data persistence

### Data Perspective
- [ ] Boundary values (min, max)
- [ ] Special characters/multi-language
- [ ] NULL/empty strings
- [ ] Invalid formats

### State Perspective
- [ ] Initial state
- [ ] Data exists state
- [ ] Error state
- [ ] Restricted state

### Environment Perspective
- [ ] Normal environment
- [ ] High-load environment
- [ ] Failure environment
```

#### Step 2: Create a Test Case Matrix

| Feature | Happy Path | Sad Path | Boundary Value | Security | Performance |
|---|---|---|---|---|---|
| User Registration | TC001 | TC002-006 | TC007 | TC010 | TC008 |
| Validation | - | TC002-006 | TC004,005,007 | - | - |
| Data Saving | TC001 | TC009 | - | - | - |

#### Step 3: Create Detailed Test Cases
- Expand the content of each cell into a detailed test case
- Break it down into executable, concrete steps
- Clearly define the expected results

### 3. Test Case Support Using AI

#### Areas Where AI Can Be Used
- **Comprehensiveness Check**: Pointing out missing test cases
- **Test Data Generation**: Proposing boundary values and abnormal values
- **Expected Value Calculation**: Calculating complex calculation results
- **Test Case Structuring**: Unifying the format

#### Areas Requiring Human Judgment
- **Understanding Business Requirements**: Domain-specific requirements
- **Risk Assessment**: Judging the impact and importance
- **Test Priority**: Execution order and resource allocation
- **Quality Standards**: Setting acceptance criteria

## Quality Checkpoints for Test Cases

### 1. Checking for Completeness

#### Feature Coverage
```markdown
## Coverage Checklist

### Each item in the API specification
- [ ] Test cases exist for all endpoints
- [ ] Test cases exist for all parameters
- [ ] Test cases exist for all response patterns

### Error Handling
- [ ] Test cases exist for all error codes
- [ ] Test cases exist for all validation rules
- [ ] Test cases exist for all exception patterns
```

#### Business Rule Coverage
```markdown
### Business Rule Verification
- [ ] Test cases exist for all business flows
- [ ] Test cases exist for all business exceptions
- [ ] Test cases exist for all permission patterns
```

### 2. Checking for Feasibility

#### Feasibility of Preparing Test Data
- Can the necessary test data be prepared?
- Can external dependent services be mocked?
- Is it possible to execute in the test environment?

#### Verifiability of Expected Results
- Can the expected results be judged objectively?
- Are the necessary tools and methods for verification available?
- Manual confirmation methods for parts that are difficult to automate

### 3. Checking for Maintainability

#### Independence of Test Cases
- Each test case can be executed independently
- Not dependent on the test order
- Can be executed in parallel

#### Response to Changes
- The scope of impact of specification changes is clear
- Test cases are easy to modify
- Test data is easy to manage

## Key Points for Human Review

### Review Perspectives

#### 1. Consistency with Business Requirements
- [ ] Are user stories tested appropriately?
- [ ] Are business rules reflected correctly?
- [ ] Are edge cases reasonable from a business perspective?

#### 2. Risk-based Priority
- [ ] Are there sufficient test cases for high-risk features?
- [ ] Are important business flows covered?
- [ ] Are security requirements tested appropriately?

#### 3. Test Efficiency
- [ ] Is the number of test cases appropriate (not too many/few)?
- [ ] Are there any duplicate test cases?
- [ ] Is the separation between automatable parts and manual tests appropriate?

### Review Process

#### Step 1: Initial Review
- Check for consistency with the specification document
- Basic check for comprehensiveness
- Point out obvious omissions or problems

#### Step 2: Detailed Review
- Check the validity of each test case
- Check the accuracy of the expected results
- Verify feasibility

#### Step 3: Final Approval
- Overall quality confirmation
- Confirmation of the test execution plan
- Decision to proceed to the next phase

## Best Practices for Test Case Creation

### 1. Phased Detailing

```markdown
Phase 1: High-level
"Test the happy and sad paths for user registration"

Phase 2: Feature-level
"Successful registration with valid data"
"Failed registration with invalid data"

Phase 3: Detailed-level
"TC001: Normal user registration"
"TC002: Duplicate email address error"
```

### 2. Strategic Design of Test Data

#### Systematization of Data Patterns
```markdown
## Basic Data Set
- Normal data: General valid values
- Boundary data: Limit values (min/max)
- Abnormal data: Invalid/illegal values
- Special data: Special characters/multi-language/NULL
```

#### Reusable Test Data
- Definition of commonly used test data
- Management of test data variations
- Automation of data creation

### 3. Precise Definition of Expected Results

#### Specific Expected Values
```markdown
❌ "It should result in an error"
✅ "HTTP 400 + {"error": "validation_failed", "field": "email"}"

❌ "It should register successfully"
✅ "HTTP 201 + return user ID + create a record in the DB"
```

#### Verifiable Conditions
- The specific value or format of the output value
- Changes in the state of the database
- The content of the log output
- Impact on external systems

## Common Problems and Countermeasures

### Problem 1: Inappropriate granularity of test cases

**Symptom**:
- Testing multiple features in one test case
- Conversely, too fine-grained, leading to high management costs

**Countermeasure**:
- 1 test case = 1 verification perspective
- Group by units that have business value

### Problem 2: Ambiguous expected results

**Symptom**:
- "Works correctly," "an error occurs," etc.
- Unclear judgment criteria

**Countermeasure**:
- Specify concrete values and states
- Be mindful of the judgment conditions in automated tests

### Problem 3: Missing test cases

**Symptom**:
- Edge cases are not considered
- Insufficient error patterns

**Countermeasure**:
- Systematic confirmation with a checklist
- Use of equivalence partitioning and boundary value analysis

### Problem 4: Lack of maintainability

**Symptom**:
- Difficult to modify test cases when specifications change
- Complicated management of test data

**Countermeasure**:
- A modular design
- Design of reusable test data

## Preparation for the Next Step

Once test case creation is complete, the next step is the [Red-Green-Refactor-Validation Cycle](./04-rgr-validation-cycle.md).

### Confirmation of Deliverables
- [ ] `testcases.md` is created in detail
- [ ] Test cases correspond to all specification items
- [ ] Expected results are defined concretely
- [ ] The review by humans is complete
- [ ] Test data can be prepared

### Quality Checklist
- [ ] **Comprehensiveness**: Happy path, sad path, and boundary values are covered
- [ ] **Clarity**: Expected results are specific and verifiable
- [ ] **Independence**: Each test case can be executed independently
- [ ] **Feasibility**: Can be executed in the test environment
- [ ] **Maintainability**: A structure that is easy to adapt to specification changes

Proper test case creation lays the foundation for the AI to generate high-quality code. The next chapter will explain in detail the implementation cycle based on these test cases.
